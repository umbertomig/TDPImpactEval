---
title:  |
        | Bottom-Up Accountability and Public Service Provision: Evidence from a Field Experiment in Brazil
author:
date: \today
abstract: "Does ~~grassroots participation~~ **local oversight** improve public service delivery? We study the effect of a mobile phone application that allows citizens to monitor school construction projects in Brazilian municipalities. ~~The app provides a platform where users can submit photos of construction sites, consult independent engineers, and contact the mayor's office about project delays.~~ **The app prompts users to submit data about construction sites, sends such crowdsourced information to independent engineers, and contacts the mayors' offices about project delays.** Our results show that the app has a null impact on the school construction indicators. Additionally, we find that politicians are unresponsive to individual requests. The results question the impact of ~~local~~ **bottom-up** monitoring on public service performance and suggest that interventions targeted ~~at other groups~~ **to other groups, or focusing on different issues,** may produce better policy outcomes."
abstractspacing: double
keywords: accountability, Brazil, impact evaluation, state capacity, technology
fontsize: 12pt
margin:
urlcolor: darkblue
linkcolor: Mahogany
citecolor: Mahogany
spacing: double
papersize: a4paper
bibliography: references.bib
biblio-style: apalike
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    number_sections: yes
    keep_tex: no
    toc: no
    template: article-template.latex
---

```{r setup, include=FALSE, warning=FALSE}
pkgs <- c("tidyverse", "dummies", "kableExtra",
          "haven", "compareGroups", "grid", "gridExtra",
          "devtools", "lubridate", "brazilmaps",
          "abjutils", "lfe", "cobalt",
          "MatchIt", "ri2", "DeclareDesign", "knitr",
          "DiagrammeR", "DiagrammeRsvg", "rsvg",
          "flextable", "officer", "ggthemes",
          "stargazer")

# Install required packages
install_if_not <- function(x) {
  if (x %in% rownames(installed.packages()) == FALSE)
    install.packages(x, dependencies = T)
}
lapply(pkgs, install_if_not)

# Load scripts
lapply(pkgs, require, character.only = T)
rm(pkgs, install_if_not)
load("tdp.RData")

# Disable scientific notation
options(scipen = 999)
```

\newpage

# Introduction
\label{sec:intro}

A robust accountability system is crucial for efficient public services
provision [@besley2003incentives; @cameron2004public; @ferejohn1986incumbent;
@o1998horizontal]. In its standard definition, accountability is understood as
the process of holding authorities responsible for their actions
[@finer1941administrative; @mulgan2000accountability; @o1990bureaucratic]. Past
studies show that accountability has a positive impact on governance; ~~as~~ it
ensures that politicians act on behalf of voters [@freire2010ngp;
@moncrieffe1998reconceptualizing], reduces the opportunities for rent-seeking
and corruption [@deininger2005does; @wenar2006accountability], and improves the
quality of public services [@adsera2003you; @bjorkman2009power]. Recent
research also suggests that accountability leads to higher economic growth
because it limits state discretion in the economy and increases long-term
investments in human capital [@benhabib2010economic; @suebvises2018social;
@ponzetto2018social].

However, accountability ~~systems take many forms~~ **mechanisms extend beyond
elections.** One promising model is that of _bottom-up monitoring_, in which
citizens receive information about the shortcomings of a given project so they
can evaluate and pressure underperforming public officials [@kosack2014does;
@molina2016community; @raffler2018weakness]. Proponents argue that bottom-up
accountability is effective because: 1) constituents have first-hand
information about the outcomes of local policies; 2) citizens have incentives
to attack corruption that directly affects themselves; 3) policy-makers are
sensitive to social punishment from their own communities [@serra2011combining,
570]. In this regard, bottom-up accountability offers a potential solution to
the principal-agent dilemma in public service by aligning the interests of
state officials with those of the constituency they serve [@barro1973control;
@raffler2018weakness].

Here we assess the impact of _Tá de Pé_ (TDP), a mobile phone application
designed to lower the costs of evaluating public works and punish political
representatives in Brazil. Developed by Transparência Brasil[^transparencia],
TDP allows citizens to learn the location of public school construction sites,
check their completion status, and anonymously request information from
competent authorities. TDP users can also take pictures of the construction
sites and submit them to independent engineers for examination. If the
engineers classify the construction as delayed, TDP prompts users to send
a message to the mayor's office asking for completion estimates and
explanations about the construction status. TDP has been online since April
2017 and was the winner of the 2016 Google Social Impact grant with more than
200,000 popular votes[^google].

[^transparencia]: Transparência Brasil is an non-governmental organisation
whose mission is to 'promote transparency and social control of public power'.
It has been active since April 2000, receives no public funding, and is
non-partisan. More information at <http://transparencia.org.br> (access: July
2019).

[^google]: About 1,000 Brazilian charities participated in the 2016 Google
Social Impact Challenge. An independent committee selected 10 organisations as
finalists, and Transparência Brasil won the challenge with about 200,000
popular votes. To know more about the contest, please visit
<https://impactchallenge.withgoogle.com/brazil2016> (access: July 2019).

We use the TDP app to conduct two experimental interventions and test ~~its
impact~~ **the impact of citizen oversight** on five outcomes related to school
completion rates and complaints to public authorities. Overall, ~~our results
show that~~ providing information to citizens has no consistent impact on
policy outcomes. In the first experiment, we find that the TDP app increased
the likelihood of construction cancellation by 2 percent, but the result does
not replicate. The remaining five models have null results. In our second
intervention, none of the estimations reach conventional levels of statistical
significance. Importantly, all coefficients are small, what suggests that even
if the TDP app had a significant effect on the outcomes, its substantive impact
would be ~~virtually~~ negligible.

The findings raise questions about the ability of citizens to hold
representatives accountable using bottom-up ~~strategies~~ **monitoring**. 
\sout{Although studies like} **On the one hand,** @bjorkman2009power,
@lagunes2018guardians, and @reinikka2005fighting report better policy outcomes
after providing information to local communities. ~~our findings are closer
to~~ **On the other hand,** @banerjee2010pitfalls, @keefer2014mass,
@lieberman2014does, @bjorkman2017experimental, @olken2007monitoring, and
@raffler2018weakness, find little evidence that information-based interventions
lead to greater government responsiveness. **Our results are in line with the
latter group and suggest that local oversight is ineffective in altering
government behaviour in Brazil.**

# The _Tá de Pé_ Project
\label{sec:tdp}

The _Tá de Pé_[^tdp] (TDP) cell phone application is an initiative carried out
by Transparência Brasil to foster bottom-up accountability in the Brazilian
public sector. More specifically, the main goal of the TDP project is to
improve responsiveness in government education expenditures. The TDP app
incentivises citizens to provide up-to-date information about unfinished school
constructions in their neighbourhoods, and that information will be assessed by
a group of independent specialists. In the case the construction is behind
schedule, TDP provides a writing platform whereby citizens can report to public
officials quickly and anonymously. The app then writes a notification to the
mayor's office, which has 15 days to reply. If they do not respond to the
request, the app forwards the notification to the Brazilian Ministry of
Education, making it harder for the municipality to access federal funds in the
future. The motivation behind this intervention is that providing information
to citizens empowers individuals to closely monitor public works. This, in
turn, results in better social outcomes as public agents become more responsive
to community demands.

[^tdp]: _Tá de Pé_ is an informal Brazilian expression for 'is it done?'.
Literally, it means 'standing on its feet' in Portuguese.

Transparência Brazil built the app in from January to March 2017 and tested it
in May of that year. The first stable Android version was deployed on Google
Play on 14 August 2017. A version for iOS came about six months later. In
October 2017, Transparência Brazil started a Facebook campaign in order to
publicise the app. Facebook is the most widely used social media network in
Brazil with around 72 million users [@statista2019facebook]. The campaigns
attracted 2,028 new users to the platform in October 2017 only.

\vspace{.2cm}

\begin{figure}
     \begin{minipage}[t]{.3\textwidth}
       \centering
       \includegraphics[scale=.2]{tdp03.jpg}
     \end{minipage}
     \hfill
     \begin{minipage}[t]{.3\textwidth}
       \centering
       \includegraphics[scale=.2]{tdp01.jpg}
     \end{minipage}
     \hfill
     \begin{minipage}[t]{.3\textwidth}
       \centering
       \includegraphics[scale=.2]{tdp02.jpg}
     \end{minipage}
		 \caption{The \textit{Tá de Pé} mobile phone application. The first image
		 presents a list of school construction sites close to the users' location.
		 The second image shows that the school construction selected by the user
		 is delayed by 9 months. The last image shows how citizens can add
		 information to the photos they submit via the app.}
		 \label{fig:screenshots} \end{figure}

Transparência Brasil partnered with the Brazilian branch of _Engineers without
Borders_ (EWB), an independent non-governmental organisation[^ewb], to provide
technical assessment of school completion rates based on user-submitted photos
and GPS coordinates. The engineers' reports are later uploaded to the TDP
database and stored on the users' mobile devices so citizens can follow the
progress of the reported constructions.

[^ewb]: Please visit <http://www.ewb-international.org> to know more about
Engineers without Borders International and <https://esf.org.br> for
information on the Brazilian office.

The TDP also received feedback from Brazilian computer scientists and policy
analists. In 2017 and 2018, Transparência Brasil announced two team programming
competitions, called 'Tá de Pé Hackathons', where contributors could fix code
bugs and suggest new functionalities to the TDP project. One of these
innovations consists of a Twitter bot (<https://twitter.com/tadepeapp>) which
posts a message on the social network each time a user submits a new picture
for evaluation or a municipality responds to a citizen's request. This allows
any interested parties, including those who do not use the TDP app, to check
the state of school construction sites.

# Experimental Design
\label{sec:design}

Between August 2017 and July 2019, we implemented two interventions to measure
the effect of the TDP app on five school construction outcomes plus a placebo
test. The outcomes are: 1) a placebo outcome indicating the percentage of the
project completed before the impact evaluation started; 2) the percentage of
the project completed by the end of the interventions; 3) the difference
between the percentage reported as completed before and after the
interventions; 4) the number of finished constructions; 5) the number of
cancelled constructions; 6) the number of schools where construction companies
updated the conclusion dates. ~~In terms of expectations,~~ Table
\ref{tab:outcomes} depicts the expected effects for each of the studied
outcomes[^more-details].

[^more-details]: **Please refer to the Online Appendix for further details on
the treatment implementation and the coding of the outcome variables.**

\begin{table}[htb!]
\centering
\caption{Outcomes and expected effect of the TDP intervention}
\label{tab:outcomes}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lcl}
\hline
\multicolumn{1}{c}{\textbf{}} & \textbf{\begin{tabular}[c]{@{}c@{}}Expected\\ impact\end{tabular}} & \multicolumn{1}{c}{\textbf{Meaning}} \\ \hline
\begin{tabular}[c]{@{}l@{}}Placebo:\\ Percentage of the project completed before\\ the impact evaluation started.\end{tabular} & Null & \begin{tabular}[c]{@{}l@{}}The placebo outcome, as reported before the intervention, \\ should have a null impact. This represents the absence of\\ differences between treatment and control prior to the\\ intervention. \vspace{.2cm} \end{tabular} \\
\begin{tabular}[c]{@{}l@{}} Outcome 1:\\ Percentage of the project reported as completed\\ by the end of the intervention period. \end{tabular} & Positive & \begin{tabular}[c]{@{}l@{}}If the intervention has a positive effect, the firms should\\  increase their efforts toward finishing the construction\\ more quickly. \vspace{.2cm} \end{tabular} \\
\begin{tabular}[c]{@{}l@{}} Outcome 2:\\ Difference between the percentage reported as\\ completed before and after the intervention. \end{tabular} & Positive & \begin{tabular}[c]{@{}l@{}}If the intervention has a positive impact, the difference\\ between before and after the intervention should reflect\\ this. \vspace{.2cm} \end{tabular} \\
\begin{tabular}[c]{@{}l@{}}Outcome 3:\\ Dummy indicator for finished constructions. \end{tabular} & Positive & \begin{tabular}[c]{@{}l@{}}If the intervention has a positive effect, more schools\\ should be reported as finished in the treatment group.\vspace{.2cm} \end{tabular} \\
\begin{tabular}[c]{@{}l@{}}Outcome 4:\\ Dummy indicator for cancelled construction. \end{tabular} & Negative & \begin{tabular}[c]{@{}l@{}}If the intervention has a positive impact, less \\ constructions should be abandoned and reported as \\ finished in the treatment group.\vspace{.2cm} \end{tabular} \\
\begin{tabular}[c]{@{}l@{}}Outcome 5:\\ Number of schools where construction \\ companies updated the conclusion dates. \end{tabular} & Positive & \begin{tabular}[c]{@{}l@{}}If the intervention has a positive effect, firms and \\ mayor's offices should be responsive to the public,\\ and update their finishing dates.\vspace{.2cm} \end{tabular} \\ \hline
\end{tabular}%
}
\end{table}

The first intervention was carried out from August 2017 to July 2018 using the
Android version of TDP. The randomisation was conducted at the municipal level.
We randomly selected `r as.numeric(table(impact_evaluation_phase1$treat)[1])`
municipalities to the control group and included 
`r format(as.numeric(table(impact_evaluation_phase1$treat)[2]),
big.mark = ",")` in the treatment group. Our control condition consists in
removing all information about school construction from the TDP app in the
chosen municipalities, so that citizens were unable to report constructions in
the control municipalities.

To evaluate the random assignment, we used the following pre-treatment
variables: 1) log of municipal population in 2015; 2) log of number of poor
families in each city; 3) log of total federal transfers to the municipality in
2016; 4) federal government indicator for primary school quality; 5) federal
government indicator for secondary school quality. The data come from the
Brazilian Ministry of Education and the 2010 Brazilian Census. Balance tests
show that the randomisation was successful and are available in the
Supplementary Materials.

We also conducted two manipulation checks and analysed the number of TDP app
downloads by municipality and over time. Figure \ref{fig:manipulation1}
displays the results and indicates that the treatment has good territorial
variability. There are `r length(unique(ga$municipality[ga$phase1==1]))`
downloads in the 
`r format(length(unique(impact_evaluation_phase1$municipality[impact_evaluation_phase1$treat=='Treatment'])),
big.mark = ",")` municipalities in the treatment condition. Downloads peak
during the Facebook TDP campaign, launched in October 2017, then diminish in
the following months. **Overall, 
`r format(sum(ga$novos_usuarios[ga$phase1==1]), big.mark = ",")` users
downloaded the app during intervention 1.**

```{r man1, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, cache=TRUE, out.width='.49\\linewidth', fig.width=4, fig.height=4, fig.show='hold', fig.align='center', fig.cap='\\label{fig:manipulation1}Manipulation checks for intervention 1. The first plot shows the geographical distribution of the treatment condition and the second graph displays the number of TDP app downloads from August 2017 to July 2018.'}

# Load data
load("tdp.RData")

# Load packages
pkgs <- c("tidyverse", "dummies", "ggpubr",
          "haven", "compareGroups",
          "devtools", "lubridate", "brazilmaps",
          "abjutils", "lfe", "cobalt",
          "MatchIt", "ri2", "DeclareDesign", "knitr",
          "DiagrammeR", "DiagrammeRsvg", "rsvg",
          "flextable", "officer", "ggthemes")
invisible(lapply(pkgs, require, character.only = T))

## Map GA intervention 1
mapbr <- get_brmap("City")
gaaux <- filter(ga, phase1 == 1)
gaaux <- select(gaaux, ibge_code7, downl)
gaaux <- rename(gaaux, City = ibge_code7)
gaaux <- unique(gaaux)
gaaux$city <- as.numeric(gaaux$City)
gaaux2 <- impact_evaluation_phase1 %>%
  select(ibge_code7) %>%
  transmute(City = as.numeric(ibge_code7)) %>%
  unique()
gaaux <- merge(gaaux2, gaaux, all.x = TRUE); rm(gaaux2)
gaaux$downl[is.na(gaaux$downl)] <- 0
gaaux2 <- data.frame(City = mapbr$City)
gaaux <- merge(gaaux2, gaaux, all.x = TRUE); rm(gaaux2)
gaaux$downl[is.na(gaaux$downl)] <- 2
gaaux$Downloads <- factor(gaaux$downl,
													labels = c("No Downloads", "Downloads", "Not in App"))
mapbr <- join_data(mapbr, gaaux, by = "City")
plot_downloads_int1 <- ggplot() +
  geom_sf(data = mapbr, aes(fill = Downloads), lwd = 0.001) +
  scale_fill_manual(values = c("#E69F00", "#0072B2", "#F0E442")) +
  theme_map()
plot_downloads_int1

# Frequency downloads
tab <- filter(ga, phase1 == 1) %>%
  group_by(data) %>%
  summarize(NewUsers = sum(novos_usuarios))
names(tab) <- c("Date", "Frequency")
plot_freq_users_int1 <- ggplot(tab, aes(x = Date, y = Frequency, group = 1)) +
  geom_line() + geom_point()
plot_freq_users_int1
```

The second intervention is similar to intervention 1 in all but three
characteristics. First, the TDP app was **then** available for both Android and
iOS devices. Second, we randomised the intervention at the school level, with
`r as.numeric(table(impact_evaluation_phase2$treat)[1])` control and 
`r format(as.numeric(table(impact_evaluation_phase2$treat)[2]), big.mark = ",",
scientific = FALSE)` treatment units. We used blocked randomisation stratified
by Brazilian states, school construction status (under construction, stopped,
unfinished), and whether the municipality spent more on school construction
that the distribution median. Finally, the intervention period lasted from
August 2018 to July 2019.

Balance tests and manipulation checks were also successful for intervention 2.
In total, `r length(unique(ga$municipality[ga$phase2==1]))` municipalities
downloaded the app. There is about 1,000 user downloads in August 2018, right
after intervention 2 starts, and a second spike around December. 
**The app gained 
`r format(sum(ga$novos_usuarios[ga$phase1==0]), big.mark = ",")` new users
during intervention 2. The number of downloads is smaller in this second
intervention as there was no associated social media campaign in that period.**

```{r man2, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, cache=TRUE, out.width='.49\\linewidth', fig.width=4, fig.height=4, fig.show='hold', fig.align='center', fig.cap='\\label{fig:manipulation2}Manipulation checks for intervention 2. The graphs display the geographical and temporal variation of TDP app downloads from August 2018 to July 2019.'}
# Load data
load("tdp.RData")

# Load packages
pkgs <- c("tidyverse", "dummies", "ggpubr",
          "haven", "compareGroups",
          "devtools", "lubridate", "brazilmaps",
          "abjutils", "lfe", "cobalt",
          "MatchIt", "ri2", "DeclareDesign", "knitr",
          "DiagrammeR", "DiagrammeRsvg", "rsvg",
          "flextable", "officer", "ggthemes")
invisible(lapply(pkgs, require, character.only = T))

## Manipulation Statistics

## Map manipulation test -- Intervention 2
mapbr <- get_brmap("City")
gaaux <- filter(ga, phase2 == 1)
gaaux <- select(gaaux, ibge_code7, downl)
gaaux <- rename(gaaux, City = ibge_code7)
gaaux <- unique(gaaux)
gaaux$City <- as.numeric(gaaux$City)
gaaux2 <- impact_evaluation_phase2 %>%
  select(ibge_code7) %>%
  transmute(City = as.numeric(ibge_code7)) %>%
  unique()
gaaux <- merge(gaaux2, gaaux, all.x = TRUE); rm(gaaux2)
gaaux$downl[is.na(gaaux$downl)] <- 0
gaaux2 <- data.frame(City = mapbr$City)
gaaux <- merge(gaaux2, gaaux, all.x = TRUE); rm(gaaux2)
gaaux$downl[is.na(gaaux$downl)] <- 2
gaaux$Downloads <- factor(gaaux$downl, labels = c("No Downloads", "Downloads",
                                                  "Not in App"))
mapbr <- join_data(mapbr, gaaux, by = "City")
p1 <- ggplot() +
  geom_sf(data = mapbr, aes(fill = Downloads), lwd = 0.001) +
  scale_fill_manual(values = c("#E69F00", "#0072B2", "#F0E442")) +
  theme_map()
p1

# Downloads over time -- Intervention 2:
# Phase 2 -- manipulation
tab <- filter(ga, phase2 == 1) %>%
  group_by(data) %>%
  summarize(NewUsers = sum(novos_usuarios))
names(tab) <- c("Date", "Frequency")
p2 <- ggplot(tab, aes(x = Date, y = Frequency, group = 1)) +
  geom_line() + geom_point()
p2
```

**Data from Google Analytics suggest that users did engage with the TDP app. On
average, each user launched `r format(round(mean(as.numeric(gsub('\\.', '',
ga2$visualizacoes_de_tela))), 1), big.mark = ",")` app sessions, which
indicates their interest in the application. In total, the app had 
`r format(sum(as.numeric(gsub('\\.', '', ga2$visualizacoes_de_tela))),
big.mark = ",", scientific = F)` screen visualisations, with an average of 
`r round(mean(as.numeric(gsub(',', '.', ga2$telas_sessao))), 2)` screen
visualisations per session.**

We estimate all models using the following regression equation:

\begin{equation}
Y_i = \alpha + \beta T_i + \gamma X_i + \theta Z_i + \varepsilon_i
\end{equation}

where $i$ indexes the experiment units. $Y_i$ is one of the six outcomes
described above, $\alpha$ is the intercept, $\beta$ denotes the average
treatment effect, and $T_i$ is a binary treatment indicator. $\gamma$ is
a vector of fixed effects, $X_i$ is a matrix of Brazilian states' fixed
effects, $\theta$ is a vector of controls, and $Z_i$ an array of controls for
the case $i$. The error term is denoted by $\varepsilon_i$. We cluster the
standard errors at the municipality level as mayors are responsible for school
investment decisions in Brazil.

# Results
\label{sec:results}

Table \ref{tab:results1} summarises the main results of intervention 1. Each
column represents the treatment effect of the TDP app on one of the outcomes we
measured for this study. All models reported here include the five control
variables described in the previous section and Brazilian states' fixed
effects. We also estimated the models without control variables, without fixed
effects, and with nearest-neighbour matching. The results are very similar to
those below.

```{r int1, echo=FALSE, warning=FALSE, message=FALSE, results='hide', cache=TRUE}
load("tdp.RData")

# Load packages
pkgs <- c("tidyverse", "dummies", "ggpubr",
          "haven", "compareGroups",
          "devtools", "lubridate", "brazilmaps",
          "abjutils", "lfe", "cobalt",
          "MatchIt", "ri2", "DeclareDesign", "knitr",
          "DiagrammeR", "DiagrammeRsvg", "rsvg",
          "flextable", "officer", "ggthemes")
invisible(lapply(pkgs, require, character.only = T))

# Auxiliary function: calculate coefficients
calc_ates <- function(outcs, treats, ctrls, fes, cls, dat, wts = NULL, ...) {
  ctrls_mod <- paste(ctrls, collapse = "+")
  fes_mod <- paste(fes, collapse = "+")
  moddescr <- data.frame()
  mods <- list()
  dataux <- dat
  k <- 1
  for (i in treats) {
    for (j in outcs) {
      if (is.null(wts)) {
        dat <- dataux %>%
          select(one_of(c(j, treats, ctrls, fes, cls))) %>%
          na.omit()
        } else {
          dat <- dataux %>%
            select(one_of(c(j, treats, ctrls, fes, cls, wts))) %>%
            na.omit()
          wts <- dat[, wts]
        }
      # No controls and no fixed effects
      mods[[k]] <- felm(as.formula(
        paste(c(j,paste(i,paste("", 0, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wts)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = F,
                                   hFEs = F))
      print(k); k = k + 1
      # Controls and no fixed effects
      mods[[k]] <- felm(as.formula(
        paste(c(j,paste(paste(c(i, ctrls_mod), collapse = "+"),
                        paste("", 0, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wts)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = T,
                                   hFEs = F))
      print(k); k = k + 1
      # No controls and fixed effects
      mods[[k]] <- felm(
        as.formula(paste(c(j, paste(paste(c(i), collapse = "+"),
                                   paste("", fes_mod, 0, cls, sep = "|"),
                                   sep = "")),
                         collapse = "~")), data = dat, weights = wts)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = F,
                                   hFEs = T))
      print(k); k = k + 1
      # Controls and fixed effects
      mods[[k]] <- felm(as.formula(
        paste(c(j,paste(paste(c(i, ctrls_mod), collapse = "+"),
                        paste("", fes_mod, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wts)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = T,
                                   hFEs = T))
      print(k); k = k + 1
    }
  }
  return(list(moddescr, mods))
}

####
## Analysis Intervention 1
####

## ATEs
outcs <- c("percExecBegin", "percExecEnd",
           "deltaPercExec", "isFinished",
           "isCancelled", "updDate")
treats <- c("treat")
ctrls <- c("logPop2015", "ideb_ai_2015","ideb_af_2015",
           "log_poorFam2010", "log_totTransf2016")
fes <- c("state")
cls <- c("municipality")

resInt1 <- calc_ates(outcs, treats, ctrls, fes, cls,
										 dat = impact_evaluation_phase1)

# Results intervention 1
stargazer(resInt1[[2]][[4]],resInt1[[2]][[8]],resInt1[[2]][[12]],
          resInt1[[2]][[16]],resInt1[[2]][[20]],resInt1[[2]][[24]],
          title = "\\label{tab:results1} Impact Evaluation -- Intervention 1",
          keep="treatTreatment",
          type = "latex",
          covariate.labels = "ATE",
          column.labels = c("Investment & Investment & Delta & Finished & Cancelled & Updated \\\\ & Before & After & Investment & Construction & Construction & Date \\\\"),
          dep.var.labels.include = F, column.sep.width = "-2pt",
          omit.stat=c("adj.rsq", "ser"), align = F, digits = 2,
          notes = "Cluster-robust SEs at the municipality level.",
          add.lines = list(c("Controls", "Yes", "Yes", "Yes",
                             "Yes", "Yes", "Yes"),
            c("State fixed effects", "Yes", "Yes", "Yes",
              "Yes", "Yes", "Yes")),
          notes.append = T, header = F)
```

\vspace{.5cm}

\begin{table}[!htbp] \centering
  \caption{\label{tab:results1} Impact Evaluation -- Intervention 1}
  \label{}
\begin{tabular}{@{\extracolsep{-2pt}}lcccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
 & \multicolumn{6}{c}{\textit{Dependent variable:}} \\
\cline{2-7}
 & Investment & Investment & Delta & Finished & Cancelled & Updated \\ & Before & After & Investment & Construction & Construction & Date \\ &  &  &  &  &  \\
\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6)\\
\hline \\[-1.8ex]
 ATE & $-$0.99 & $-$1.12 & $-$0.13 & 0.002 & 0.02$^{**}$ & 0.05 \\
  & (2.59) & (2.96) & (1.03) & (0.01) & (0.01) & (0.05) \\
  & & & & & & \\
\hline \\[-1.8ex]
Controls & Yes & Yes & Yes & Yes & Yes & Yes \\
State fixed effects & Yes & Yes & Yes & Yes & Yes & Yes \\
Observations & 2,986 & 2,986 & 2,986 & 2,986 & 2,986 & 2,926 \\
R$^{2}$ & 0.16 & 0.14 & 0.05 & 0.02 & 0.07 & 0.13 \\
\hline
\hline \\[-1.8ex]
\textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\
 & \multicolumn{6}{r}{Cluster-robust SEs at the municipality level.} \\
\end{tabular}
\end{table}

We find that the app only has a small effect on cancellation rates. The TDP
application increases the likelihood of cancelling the construction in 
`r round(100*resInt1[[2]][[20]]$coefficients[1], 2)` percent. While this result
goes in the opposite direction of our theoretical expectations, the finding is
inconsistent and does not replicate in the second experiment. All other
coefficients are not statistically significant at conventional levels. On the
one hand, the results indicate that our placebo outcome, the percentage of the
invested executed before the intervention, indeed behaves as predicted. On the
other hand, we expected the five remaining outcomes to improve after the
introduction of the app. The literature on bottom-up accountability argues that
delivering more information about the shortcomings of public services provision
will ~~mobilise citizens who, in turn, would pressure state agents to produce
better social policies~~ **put citizens in a position where they can monitor
state agents and improve provider behaviour** [@raffler2018weakness]. Our
results do not lend support to that hypothesis.

Table \ref{tab:results2} shows the results of the second intervention. The
treatment does not have a statistically significant effect on any our outcomes
of interest, including the placebo. This raises further questions about the
effect of the TDP app on school completion. Note that the effect signs are also
inconsistent with improving the outcomes, what demonstrates that our results do
not derive from low statistical power or the reduced control group size.

```{r int2, echo=FALSE, warning=FALSE, message=FALSE, results='hide',cache=TRUE}
load("tdp.RData")

# Load packages
pkgs <- c("tidyverse", "dummies", "ggpubr",
          "haven", "compareGroups",
          "devtools", "lubridate", "brazilmaps",
          "abjutils", "lfe", "cobalt",
          "MatchIt", "ri2", "DeclareDesign", "knitr",
          "DiagrammeR", "DiagrammeRsvg", "rsvg",
          "flextable", "officer", "ggthemes",
          "stargazer")
invisible(lapply(pkgs, require, character.only = T))

# Auxiliary function: calculate coefficients
calc_ates <- function(outcs, treats, ctrls, fes, cls, dat, wts = NULL, ...) {
  ctrls_mod <- paste(ctrls, collapse = "+")
  fes_mod <- paste(fes, collapse = "+")
  moddescr <- data.frame()
  mods <- list()
  dataux <- dat
  k <- 1
  for (i in treats) {
    for (j in outcs) {
      if (is.null(wts)) {
        dat <- dataux %>%
          select(one_of(c(j, treats, ctrls, fes, cls))) %>%
          na.omit()
        wtsaux <- NULL
      } else {
          dat <- dataux %>%
            select(one_of(c(j, treats, ctrls, fes, cls, wts))) %>%
            na.omit()
          wtsaux <- dat[, wts]
      }
      # No controls and no fixed effects
      mods[[k]] <- felm(as.formula(
        paste(c(j,paste(i,paste("", 0, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wtsaux)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = F,
                                   hFEs = F))
      print(k); k = k + 1
      # Controls and no fixed effects
      mods[[k]] <- felm(as.formula(
        paste(c(j,paste(paste(c(i, ctrls_mod), collapse = "+"),
                        paste("", 0, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wtsaux)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = T,
                                   hFEs = F))
      print(k); k = k + 1
      # No controls and fixed effects
      mods[[k]] <- felm(
        as.formula(paste(c(j,paste(paste(c(i), collapse = "+"),
                                   paste("", fes_mod, 0, cls, sep = "|"),
                                   sep = '')),
                         collapse = "~")), data = dat, weights = wtsaux)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = F,
                                   hFEs = T))
      print(k); k = k + 1
      # Controls and fixed effects
      mods[[k]] <- felm(as.formula(
        paste(c(j, paste(paste(c(i, ctrls_mod), collapse = "+"),
                        paste("", fes_mod, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wtsaux)
      moddescr <- rbind(moddescr,
                        data.frame(outc = j,
                                   treat = i,
                                   hCtrls = T,
                                   hFEs = T))
      print(k); k = k + 1
    }
  }
  return(list(moddescr, mods))
}

outcs <- c("percExecBegin", "percExecEnd",
           "deltaPercExec", "isFinished",
           "isCancelled", "updDate")
ctrls <- c("logPop2015", "ideb_ai_2015","ideb_af_2015",
           "log_poorFam2010", "log_totTransf2016")
fes <- c("state")
cls <- c("municipality")

res_int2 <- calc_ates(outcs, "treat", ctrls, fes, cls, dat = impact_evaluation_phase2, wts = "IPW_treat")

# Results intervention 2
library(stargazer)
stargazer(res_int2[[2]][[4]],res_int2[[2]][[8]],res_int2[[2]][[12]],
          res_int2[[2]][[16]],res_int2[[2]][[20]],res_int2[[2]][[24]],
          title = "\\label{tab:results2} Impact Evaluation -- Intervention 2",
          dep.var.labels.include = F,
          keep="treatTreatment", type = "latex",
          covariate.labels = "ATE",
          column.labels = c("Investment & Investment & Delta & Finished & Cancelled & Updated \\\\ & Before & After & Investment & Construction & Construction & Date \\\\"),
          column.sep.width = "-2pt",
          omit.stat = c("adj.rsq", "ser"), align = F, digits = 2,
          notes = c("Cluster-robust SEs at the municipality level.",
										"IPW computed by the randomizr package."),
          add.lines = list(c("Controls", "Yes", "Yes", "Yes", 
														 "Yes", "Yes", "Yes"),
            c("State Fixed Effects", "Yes", "Yes", "Yes", "Yes", "Yes", "Yes")),
          notes.append = T, header = F)
```

\vspace{.5cm}

\begin{table}[!htbp] \centering
  \caption{\label{tab:results2} Impact Evaluation -- Intervention 2}
  \label{}
\begin{tabular}{@{\extracolsep{-2pt}}lcccccc}
\\[-1.8ex]\hline
\hline \\[-1.8ex]
 & \multicolumn{6}{c}{\textit{Dependent variable:}} \\
\cline{2-7}
 & Investment & Investment & Delta & Finished & Cancelled & Updated \\ & Before & After & Investment & Construction & Construction & Date \\ &  &  &  &  &  \\
\\[-1.8ex] & (1) & (2) & (3) & (4) & (5) & (6)\\
\hline \\[-1.8ex]
 ATE & $-$1.33 & $-$2.26 & $-$0.94 & $-$0.001 & 0.01 & 0.002 \\
  & (1.45) & (1.56) & (0.61) & (0.01) & (0.01) & (0.02) \\
  & & & & & & \\
\hline \\[-1.8ex]
Controls & Yes & Yes & Yes & Yes & Yes & Yes \\
State Fixed Effects & Yes & Yes & Yes & Yes & Yes & Yes \\
Observations & 3,226 & 3,226 & 3,226 & 3,226 & 3,226 & 3,109 \\
R$^{2}$ & 0.12 & 0.11 & 0.04 & 0.02 & 0.17 & 0.09 \\
\hline
\hline \\[-1.8ex]
\textit{Note:}  & \multicolumn{6}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\
 & \multicolumn{6}{r}{Cluster-robust SEs at the municipality level.} \\
 & \multicolumn{6}{r}{IPW computed by the randomizr package.} \\
\end{tabular}
\end{table}

Figure \ref{fig:randomisation-inference} shows the results of our randomisation
inference tests. Randomisation inference allows us to estimate the probability
of the sharp null hypothesis over all possible randomisations that could have
occurred under our research design [@coppock2019ri2; @gerber2012field]. We fail
to reject the null in all but the finished school indicator in experiment 1.

```{r ri, echo=FALSE, warning=FALSE, message=FALSE, results='hide', cache=TRUE, fig.width=7, fig.height=8, fig.show='hold', fig.align='center', fig.cap='\\label{fig:randomisation-inference}Sampling distribution of the estimated coefficient for our six outcomes in two interventions. Graphs on the left correspond to randomisation inference estimates for intervention 1 and those on the right describe the results for intervention 2.'}
# Chunk randomization inference
load("tdp.RData")

# Load packages
pkgs <- c("tidyverse", "dummies",
          "haven", "compareGroups",
          "devtools", "lubridate", "brazilmaps",
          "abjutils", "lfe", "cobalt",
          "MatchIt", "ri2", "DeclareDesign", "knitr",
          "DiagrammeR", "DiagrammeRsvg", "rsvg",
          "flextable", "officer", "ggthemes", "ggpubr")
invisible(lapply(pkgs, require, character.only = T))

# Function for custom randomization inference
test_fun <- function(dat, outc, treat, wts = NULL) {
  ctrls_mod <- paste(ctrls, collapse = "+")
  fes_mod <- paste(fes, collapse = "+")
  moddescr <- data.frame()
  mods <- list()
  if (is.null(wts)) {
    dat <- dat %>%
      select(one_of(c(outc, treat, ctrls, fes, cls))) %>%
      na.omit()
    wtsaux <- NULL
  } else {
    dat <- dat %>%
      select(one_of(c(outc, treat, ctrls, fes, cls, wts))) %>%
      na.omit()
    wtsaux <- dat[, wts]
  }
  aux <-
    felm(as.formula(
      paste(c(outc,paste(paste(c(treat,ctrls_mod), collapse = "+"),
                        paste("", fes_mod, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wtsaux)
  return(aux$coefficients[1])
}

outcs <- c("percExecBegin", "percExecEnd",
           "deltaPercExec", "isFinished",
           "isCancelled", "updDate")
ctrls <- c("logPop2015", "ideb_ai_2015","ideb_af_2015",
           "log_poorFam2010", "log_totTransf2016")
fes <- c("state")
cls <- c("municipality")

# First experiment
set.seed(543129) #Random.org
auxdat <- impact_evaluation_phase1[,c("ibge_code7", outcs, ctrls, fes, cls)]
aux2 <- unique(impact_evaluation_phase1[,c("ibge_code7", "treat")]) %>% na.omit()
N = sum(table(aux2$treat))
Ctrl = 150
resri1 <- data.frame(1:1000)
for (k in 1:1000) {
    treat <- c(rep(1, N-Ctrl), rep(0, Ctrl))
    treat <- sample(treat, N)
    aux2 <- data.frame(aux2, treat = treat)
}
auxdat <- left_join(auxdat, aux2)
for (i in outcs) {
  res <- numeric()
  for (k in 1:1000)
    res[k] <- test_fun(auxdat, i, paste("treat", k, sep = "."))
  resri1 <- data.frame(resri1, res)
  names(resri1)[names(resri1) == "res"] = i
}
resri1 <- resri1[, -1]
i1h1 <- ggplot(data = resri1, aes(resri1$percExecBegin)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase1, "percExecBegin", "treat"),
             lwd = 1, lty = 2) +
  labs(x = "Percentage Completed Before\n(placebo)", y = "Frequency")
i1h2 <- ggplot(data=resri1, aes(resri1$percExecEnd)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase1, "percExecEnd", "treat"),
             lwd = 1, lty = 2) +
  labs(x = "Percentage Completed End Intervention", y = "Frequency")
i1h3 <- ggplot(data = resri1, aes(resri1$deltaPercExec)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase1, "deltaPercExec", "treat"),
             lwd = 1, lty = 2) +
  labs(x = "Diff. Pct. Completed Before and After", y = "Frequency")
i1h4 <- ggplot(data = resri1, aes(resri1$isFinished)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase1, "isFinished", "treat"),
             lwd = 1, lty = 2) +
  labs(x = "Finished School Construction Indicator", y = "Frequency")
i1h5 <- ggplot(data = resri1, aes(resri1$isCancelled)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase1, "isCancelled", "treat"),
             lwd = 1, lty = 2) +
  labs(x = "Cancelled School Construction Indicator", y = "Frequency")
i1h6 <- ggplot(data = resri1, aes(resri1$updDate)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase1, "updDate", "treat"),
             lwd = 1, lty = 2) +
  labs(x = "Updated Endline Date School Construction", y = "Frequency")

## Intervention 2
# Declare RA
aux <- filter(rand2018, !is.na(Z_intheapp))
delc_ra <- declare_ra(blocks = aux$var_blocking,
                     prob_each = c(.85,.15),
                     conditions = c(1, 0))

# Function for custom randomization inference
test_fun <- function(dat, outc, treat, wts = NULL) {
  ctrls_mod <- paste(ctrls, collapse = "+")
  fes_mod <- paste(fes, collapse = "+")
  moddescr <- data.frame()
  mods <- list()
  if (is.null(wts)) {
    dat <- dat %>%
      select(one_of(c(outc, treat, ctrls, fes, cls))) %>%
      na.omit()
    wtsaux <- NULL
  } else {
    dat <- dat %>%
      select(one_of(c(outc, treat, ctrls, fes, cls, wts))) %>%
      na.omit()
    wtsaux <- dat[, wts]
  }
  aux <-
    felm(as.formula(
      paste(c(outc,paste(paste(c(treat,ctrls_mod), collapse = "+"),
                        paste("", fes_mod, 0, cls, sep = "|"), sep = "")),
              collapse = "~")), data = dat, weights = wtsaux)
  return(aux$coefficients[1])
}

outcs <- c("percExecBegin", "percExecEnd",
           "deltaPercExec", "isFinished",
           "isCancelled", "updDate")
ctrls <- c("logPop2015", "ideb_ai_2015","ideb_af_2015",
           "log_poorFam2010", "log_totTransf2016")
fes <- c("state")
cls <- c("municipality")

# First experiment
set.seed(543129) #Random.org
auxdat <- impact_evaluation_phase2[, c("id_project", outcs, ctrls, fes, cls)]
aux2 <- unique(aux[,c("id", "Z_intheapp", "IPW_intheapp")]) %>%
  na.omit() %>%
  rename(id_project = id,
         treat = Z_intheapp,
         wts = IPW_intheapp) %>%
  mutate(treat = as.numeric(as.factor(treat)) - 1)
resri2 <- data.frame(1:1000)
for (k in 1:1000) {
    Z <- block_ra(blocks = aux$var_blocking,
                  conditions = c(1, 0),
                  prob_each = c(.85, .15))
    IPW <- 1/obtain_condition_probabilities(delc_ra, Z)
    aux2 <- data.frame(aux2, treat = Z, wts = IPW)
}
auxdat <- left_join(auxdat, aux2)
for (i in outcs) {
  res <- numeric()
  for (k in 1:1000)
    res[k] <- test_fun(auxdat, i, paste("treat", k, sep = "."),
                       wts = paste("wts", k, sep = "."))
  resri2 <- data.frame(resri2, res)
  names(resri2)[names(resri2) == "res"] = i
}
resri2 <- resri2[, -1]
i2h1 <- ggplot(data = resri2, aes(resri2$percExecBegin)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase2,
                                   "percExecBegin", "treat", wts = "IPW_treat"),
             lwd = 1, lty = 2) +
  labs(x = "Percentage Completed Before\n(placebo)", y = "Frequency")
i2h2 <- ggplot(data=resri2, aes(resri2$percExecEnd)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase2,
                                   "percExecEnd", "treat", wts = "IPW_treat"),
             lwd = 1, lty = 2) +
  labs(x = "Percentage Completed End Intervention", y = "Frequency")
i2h3 <- ggplot(data = resri2, aes(resri2$deltaPercExec)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase2,
                                   "deltaPercExec", "treat", wts = "IPW_treat"),
             lwd = 1, lty = 2) +
  labs(x = "Diff. Pct. Completed Before and After", y = "Frequency")
i2h4 <- ggplot(data=resri2, aes(resri2$isFinished)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase2,
                                   "isFinished", "treat", wts = "IPW_treat"),
             lwd = 1, lty = 2) +
  labs(x = "Finished School Construction Indicator", y = "Frequency")
i2h5 <- ggplot(data=resri2, aes(resri2$isCancelled)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase2,
                                   "isCancelled", "treat", wts = "IPW_treat"),
             lwd = 1, lty = 2) +
  labs(x = "Cancelled School Construction Indicator", y = "Frequency")
i2h6 <- ggplot(data = resri2, aes(resri2$updDate)) +
  geom_histogram(bins = 100) +
  geom_vline(xintercept = test_fun(impact_evaluation_phase2,
                                   "updDate", "treat", wts = "IPW_treat"),
             lwd = 1, lty = 2) +
  labs(x = "Updated Endline Date School Construction", y = "Frequency")

ggarrange(i1h1, i2h1,
          i1h2, i2h2,
          i1h3, i2h3,
          i1h4, i2h4,
          i1h5, i2h5,
          i1h6, i2h6,
          labels = rep(c("Int. 1", "Int. 2"), 6),
          label.x = .16, label.y = .9,
          font.label = list(size = 12, color = "black", face = "plain"),
          ncol = 2, nrow = 6)
```

We also note that effect sizes are small in all estimations and that the
coefficients flip signs in all but one of our six dependent variables. This
provides further evidence for the null results: not only the app would have
a low impact even if the treatment were significant, but the results could go
against what the bottom-up accountability theory predicts. At least in the
school construction outcomes we investigate here, we find little evidence that
grassroots monitoring works in the context of school constructions in Brazil.

# Discussion
\label{sec:discussion}

In this paper, we discuss **whether delivering information to citizens via** a
mobile phone application fosters ~~grassroots mobilisation~~ **community
oversight** and political accountability in Brazil. Our two interventions show
that the results are at best mixed. Although we find ~~an~~ **some treatment**
effect on school cancelling rates in the first intervention, the app has no
consistent impact on our outcomes of interest. These findings add to the
studies that cast doubts on the relationship between bottom-up accountability
and local policy performance [e.g., @banerjee2010pitfalls; @lieberman2014does;
@raffler2018weakness].

What factors, then, are driving these results? It seems unlikely that the null
results derive from flaws in the research design. First, our study is well
powered. Although the treatment is indirect---the person has to download the
app, find a school construction, and then report it---,we included
a substantial number of schools in the treatment groups. Second, balance and
manipulation tests indicate that the treatment allocation was successful, so we
can rule out problems in the randomisation procedures. **Third, data from
Google Analytics confirm that citizens indeed used the app and provided
information to our dataset. This indicates that the treatment manipulation was
effective. In this sense, it is unlikely that our results derive from low user
response.** Fourth, after doing a series of robustness tests, we still find no
firm evidence of treatment effect. Finally, note that the sign of the
coefficients are frequently contrary to our theoretical expectations. This
rules out a possible concern about statistical power with our small control
group approach.

**We discuss some possible reasons why community monitoring did not work in our
case**. ~~A~~ **One** plausible explanation is that individuals were unable to
differentiate the effect of political corruption from those of spending cuts.
Due to the severe economic crisis in 2014--2016, the Brazilian federal
government introduced discretionary spending limits that affected public
investment [@rossi2016impactos]. Politicians may argue that
delays in school constructions are not derived from their misuse of government
funds, but from the austerity measures. If this is the case, citizens will not
blame local politicians for the underprovision of public goods. Consequently,
representatives can dismiss individual requests as the issue is unlikely to
escalate.

**The electoral cycle might also have decreased the potential effect of the
treatment. As the experiment was fielded right after Brazil's municipal
elections, incumbents might have disregarded the requests because they did not
see the demands as politically costly in the short run. Having just taken
office, mayors might have focused their attention to the formation of
government coalitions or to budget concerns. Future research may evaluate how
electoral dynamics interact with citizen oversight, potentially by replicating
informational experiments in different stages of the political cycle.**

\sout{Moreover, it is possible that a mobile app like TDP is simply not
sufficient to promote collective action. Raffler et al (2018, 29) point
out several reasons why information interventions does not lead to higher
pressure on public agents, such as citizens' apathy towards their ability to
make public agents accountable, lack of official channels to support popular
demands, or that constituents have more pressing needs than monitoring
representatives. Furthermore, individuals may also believe they are better off
by free-riding on other users of the TDP app, thus reaping the benefits of
having faster school constructions without incurring personal costs (Olson
1965).}

In sum, our experiments suggest that popular participation and bottom-up
monitoring may not be effective to improve public service delivery in the case
of school constructions in Brazil. Nevertheless, the null findings are
informative to researchers and policy-makers. The most important recommendation
derived from this study is that interventions targeting elite groups, such as
lobbyists or civil servants, might render better ~~policy~~ **school
construction** outcomes than those focused at the ~~grassroots levels~~
**community level**. Another core lesson is that although digital interventions
are promising means to deliver information, perhaps they do not have the same
impact as personal, face-to-face communication. Since many developing countries
share Brazil's issues with education provision, the shortcomings we describe
here serve as warnings for future interventions. Finally, whether this study
generalises beyond school constructions to other bottom-up programs, and to
other contexts, remains to be studied.

\setlength{\parindent}{0cm}
\setlength{\parskip}{5pt}
